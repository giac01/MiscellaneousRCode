---
title: "NN1: The Effect of Selection Bias & Range Restriction"
author: "Giacomo Bignardi (& Claude)"
format:
  html:
    toc: true
    code-fold: false
    embed-resources: true
---

*Created with ClaudeAI for teaching purposes.*

## Introduction

Range restriction occurs when we only observe a subset of the full range of a variable. This commonly happens in:

- Selected samples (e.g., studies of undergraduate students)
- Truncated samples (e.g., only employees who passed screening)

When we restrict the range of a predictor variable, the observed correlation **underestimates** the true population correlation.

## Simulation Setup

Let's simulate data from a simple linear regression model:

$$Y = 1 + 0.5X + \epsilon$$

where $\epsilon \sim N(0, 1)$.

```{r}
#| label: setup
#| message: false

library(ggplot2)
library(dplyr)

set.seed(42)

# Generate large dataset for precise calculations
n_calc <- 100000
x_calc <- rnorm(n_calc, mean = 0, sd = 1)
y_calc <- 1 + 0.5 * x_calc + rnorm(n_calc, mean = 0, sd = 1)
calc_data <- data.frame(x = x_calc, y = y_calc)

# Generate smaller dataset for plotting
n_plot <- 2000
x_plot <- rnorm(n_plot, mean = 0, sd = 1)
y_plot <- 1 + 0.5 * x_plot + rnorm(n_plot, mean = 0, sd = 1)
plot_data <- data.frame(x = x_plot, y = y_plot)

# Use calc_data for statistics
full_data <- calc_data
```

## Full Range Analysis

First, let's examine the correlation and R² with the full range of X.

```{r}
#| label: full-range

# Full range statistics
full_cor <- cor(full_data$x, full_data$y)
full_model <- lm(y ~ x, data = full_data)
full_r2 <- summary(full_model)$r.squared

cat("Full Range Statistics:\n")
cat(sprintf("  Correlation: %.3f\n", full_cor))
cat(sprintf("  R-squared:   %.3f\n", full_r2))
cat(sprintf("  X range:     %.2f to %.2f\n", min(full_data$x), max(full_data$x)))
```

## Visualizing Range Restriction Effects

Now let's see what happens when we restrict the range of X to different intervals.

```{r}
#| label: restriction-demo
#| fig-width: 10
#| fig-height: 8

# Define different restriction ranges (centered around mean of 0)
restrictions <- list(
  "Full Range" = c(-Inf, Inf),
  "|X| < 1.5" = c(-1.5, 1.5),
  "|X| < 1" = c(-1, 1),
  "|X| < 0.5" = c(-0.5, 0.5)
)

# Calculate statistics for each restriction
results <- data.frame(
  Restriction = character(),
  Correlation = numeric(),
  R_squared = numeric(),
  N = integer(),
  X_min = numeric(),
  X_max = numeric(),
  stringsAsFactors = FALSE
)

for (name in names(restrictions)) {
  range_vals <- restrictions[[name]]
  subset_data <- full_data %>%
    filter(x >= range_vals[1] & x <= range_vals[2])

  if (nrow(subset_data) > 2) {
    r <- cor(subset_data$x, subset_data$y)
    model <- lm(y ~ subset_data$x, data = subset_data)
    r2 <- summary(model)$r.squared

    results <- rbind(results, data.frame(
      Restriction = name,
      Correlation = r,
      R_squared = r2,
      N = nrow(subset_data),
      X_min = min(subset_data$x),
      X_max = max(subset_data$x)
    ))
  }
}

# Display results table
knitr::kable(results,
             digits = 3,
             col.names = c("Restriction", "r", "R²", "N", "X min", "X max"),
             caption = "Effect of Range Restriction on Correlation and R²")
```

## Visual Demonstration

```{r}
#| label: visual-demo
#| fig-width: 10
#| fig-height: 10

# Create plots for each restriction
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0), cex.lab = 2, cex.axis = 2, cex.main = 2)

for (i in seq_along(restrictions)) {
  name <- names(restrictions)[i]
  range_vals <- restrictions[[name]]

  # Color points based on whether they're in the restricted range (use plot_data for visualization)
  in_range <- plot_data$x >= range_vals[1] & plot_data$x <= range_vals[2]

  plot(plot_data$x, plot_data$y,
       col = ifelse(in_range, "steelblue", "gray80"),
       pch = 19, cex = 0.8,
       xlab = "X", ylab = "Y",
       main = paste0(name, "\nr = ", round(results$Correlation[i], 3),
                    ", R² = ", round(results$R_squared[i], 3)))

  # Add true regression line with known parameters
  abline(a = 1, b = 0.5, col = "darkblue", lwd = 2)

  # Add vertical lines showing restriction boundaries
  if (is.finite(range_vals[1])) {
    abline(v = range_vals[1], col = "red", lty = 2)
  }
  if (is.finite(range_vals[2])) {
    abline(v = range_vals[2], col = "red", lty = 2)
  }
}

# Add overall title with the regression formula
mtext(expression(Y == 1 + 0.5 * X + epsilon), outer = TRUE, cex = 2)
```

## Binary Predictor Example: Food Security

Range restriction also occurs with binary predictors when the groups are not evenly large. Let's simulate an outcome where food insecurity increases a health outcome by 5 units:

$$Y = 0 + 5 \times \text{FoodInsecure} + \epsilon$$

where $\epsilon \sim N(0, 10)$.

```{r}
#| label: binary-setup

set.seed(123)

# Function to generate data with a given prevalence of food security
generate_binary_data <- function(n, prop_secure) {
  food_secure <- rbinom(n, 1, prop_secure)
  food_insecure <- 1 - food_secure
  y <- 0 + 5 * food_insecure + rnorm(n, mean = 0, sd = sqrt(10))
  data.frame(
    food_secure = food_secure,
    food_insecure = food_insecure,
    y = y
  )
}

# Prevalences to test (proportion food secure)
prevalences <- c(0.50, 0.90, 0.95, 0.995)
prevalence_labels <- c("50%", "90%", "95%", "99.5%")

# Generate large datasets for calculations
n_calc_binary <- 100000
calc_datasets <- lapply(prevalences, function(p) generate_binary_data(n_calc_binary, p))

# Generate smaller datasets for plotting
n_plot_binary <- 4000
plot_datasets <- lapply(prevalences, function(p) generate_binary_data(n_plot_binary, p))

# Calculate statistics for each prevalence
binary_results <- data.frame(
  Prevalence = character(),
  Correlation = numeric(),
  R_squared = numeric(),
  N_secure = integer(),
  N_insecure = integer(),
  stringsAsFactors = FALSE
)

for (i in seq_along(prevalences)) {
  data <- calc_datasets[[i]]
  r <- cor(data$food_insecure, data$y)
  model <- lm(y ~ food_insecure, data = data)
  r2 <- summary(model)$r.squared

  binary_results <- rbind(binary_results, data.frame(
    Prevalence = prevalence_labels[i],
    Correlation = r,
    R_squared = r2,
    N_secure = sum(data$food_secure),
    N_insecure = sum(data$food_insecure)
  ))
}

knitr::kable(binary_results,
             digits = 3,
             col.names = c("Food Secure %", "r", "R²", "N Secure", "N Insecure"),
             caption = "Effect of Prevalence on Correlation with Binary Predictor")
```

## Visual Demonstration: Binary Predictor

```{r}
#| label: binary-visual
#| fig-width: 10
#| fig-height: 10

par(mfrow = c(2, 2), oma = c(0, 0, 2, 0), cex.lab = 2, cex.axis = 2, cex.main = 2)

for (i in seq_along(prevalences)) {
  data <- plot_datasets[[i]]

  # Jitter x for visualization
  x_jitter <- data$food_insecure + runif(nrow(data), -0.1, 0.1)

  plot(x_jitter, data$y,
       col = ifelse(data$food_insecure == 1,
                    adjustcolor("coral", alpha.f = 0.5),
                    adjustcolor("steelblue", alpha.f = 0.5)),
       pch = 19, cex = 0.8,
       xlab = "Food Security", ylab = "Depression Symptom Score",
       xlim = c(-0.3, 1.3),
       xaxt = "n",
       main = paste0("Food Secure: ", prevalence_labels[i],
                    "\nr = ", round(binary_results$Correlation[i], 3),
                    ", R² = ", round(binary_results$R_squared[i], 3)))

  axis(1, at = c(0, 1), labels = c("0\n(Secure)", "1\n(Insecure)"))

  # Add group means from full calculation dataset
  calc_data <- calc_datasets[[i]]
  mean_secure <- mean(calc_data$y[calc_data$food_insecure == 0])
  mean_insecure <- mean(calc_data$y[calc_data$food_insecure == 1])
  points(c(0, 1), c(mean_secure, mean_insecure), pch = 18, cex = 3, col = "black")
  segments(0, mean_secure, 1, mean_insecure, col = "black", lwd = 2)
}

mtext(expression(Y == 0 + 5 %*% FoodSecurity + epsilon ),
      outer = TRUE, cex = 1.8)
```

## Collider Bias: Concert Attendance Example

Collider bias occurs when we condition on a common effect (collider) of two variables. This can create spurious associations that don't exist in the population.

**Setup:**

- **Exposure:** Income
- **Outcome:** Taylor Swift Fandom
- **Collider:** Concert Attendance (affected by both income AND fandom)

In the population, income and fandom are **independent**. But both increase the probability of concert attendance. When we only analyze concert attendees, we induce a spurious negative association: among attendees, those with lower income must have higher fandom to afford tickets, and vice versa.

```{r}
#| label: collider-setup

set.seed(2024)

n <- 100000

# Generate independent exposure and outcome
income <- rnorm(n, mean = 50, sd = 15)  # Income in thousands
fandom <- rnorm(n, mean = 50, sd = 15)  # Fandom score (0-100 scale)

# Concert attendance depends on BOTH income and fandom (collider)
# Higher income OR higher fandom → more likely to attend
attendance_prob <- plogis(-11 + .1 * income + .1 * fandom)
concert_attendance <- rbinom(n, 1, attendance_prob)

collider_data <- data.frame(
  income = income,
  fandom = fandom,
  concert_attendance = concert_attendance
)

# Summary statistics
cat("Sample sizes:\n")
cat(sprintf("  Total:     %d\n", n))
cat(sprintf("  Attendees: %d (%.1f%%)\n",
            sum(concert_attendance),
            100 * mean(concert_attendance)))
```

```{r}
#| label: collider-analysis

# Regression in full sample (true relationship = none)
model_full <- lm(fandom ~ income, data = collider_data)

# Regression only among concert attendees (biased!)
attendees <- collider_data[collider_data$concert_attendance == 1, ]
model_attendees <- lm(fandom ~ income, data = attendees)

# Extract coefficients
coef_full <- coef(model_full)
coef_attend <- coef(model_attendees)

cat("\nFull Sample (True relationship):\n")
cat(sprintf("  Fandom = %.2f + %.3f × Income\n", coef_full[1], coef_full[2]))
cat(sprintf("  Correlation: %.3f\n", cor(collider_data$income, collider_data$fandom)))

cat("\nConcert Attendees Only (Collider bias):\n")
cat(sprintf("  Fandom = %.2f + %.3f × Income\n", coef_attend[1], coef_attend[2]))
cat(sprintf("  Correlation: %.3f\n", cor(attendees$income, attendees$fandom)))
```

```{r}
#| label: collider-plot
#| fig-width: 12
#| fig-height: 6

par(mfrow = c(1, 2), cex.lab = 1.4, cex.axis = 1.2, cex.main = 1.4)

# Plot 1: Full sample
plot(collider_data$income, collider_data$fandom,
     col = ifelse(collider_data$concert_attendance == 1,
                  adjustcolor("coral", alpha.f = 0.6),
                  adjustcolor("steelblue", alpha.f = 0.3)),
     pch = 19, cex = 0.8,
     xlab = "Income ($k)", ylab = "Taylor Swift Fandom Score",
     main = "Full Sample: No Association")

abline(model_full, col = "darkblue", lwd = 3)

# Annotate regression formula
text(95, 85,
     bquote(Fandom == .(round(coef_full[1], 1)) + .(round(coef_full[2], 3)) %*% Income + epsilon),
     col = "darkblue", cex = 1.2, adj = 1)
text(95, 78,
     bquote(r == .(round(cor(collider_data$income, collider_data$fandom), 3))),
     col = "darkblue", cex = 1.2, adj = 1)

legend("bottomright",
       legend = c("Attended concert", "Did not attend"),
       col = c("coral", "gray70"), pch = 19, cex = 1)

# Plot 2: Concert attendees only
plot(attendees$income, attendees$fandom,
     col = adjustcolor("coral", alpha.f = 0.6),
     pch = 19, cex = 0.8,
     xlab = "Income ($k)", ylab = "Taylor Swift Fandom Score",
     main = "Concert Attendees Only: \nSpurious Negative Association")

abline(model_attendees, col = "darkred", lwd = 3)

# Annotate regression formula
text(95, 85,
     bquote(Fandom == .(round(coef_attend[1], 1)) + .(round(coef_attend[2], 3)) %*% Income),
     col = "darkred", cex = 1.2, adj = 1)
text(95, 78,
     bquote(r == .(round(cor(attendees$income, attendees$fandom), 3))),
     col = "darkred", cex = 1.2, adj = 1)
```

**Interpretation:** In the full sample, there is essentially no relationship between income and Taylor Swift fandom (as expected—they are independent). However, when we restrict our analysis to only concert attendees (conditioning on the collider), we observe a spurious negative association. This happens because attending a concert requires either high income (to afford tickets) or high fandom (motivation to find a way), so among attendees, those with lower income tend to have higher fandom, creating the illusion of a negative relationship.

